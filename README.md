# SLAM_MRE462
GITHUB for MRE 462 SLAM Project

Part 1: 
https://www.mathworks.com/help/vision/ug/monocular-visual-simultaneous-localization-and-mapping.html


Results will be uploaded


How would V-Slam be implemented? 
Using Matlab, you could load in a video where the camera would identify distinctive features. These could be edges or corners, could even be shadows. Then as the camera begins to move, the code tracks the features location. Those locations are stored as "key points" Once you complete the loop around the desk, based on the perceived depth could determine the camera's distance from the points. In addition, from the graph you create an outline of the environment filmed based on the key points.  
Based on the code in Part I, you had the code estimate the camera's location, and then the actual location. They were very close to each other based on the graph. 



Part 2: https://youtu.be/Rzt67A7-dKw
.m file and images of results will be provided in github
